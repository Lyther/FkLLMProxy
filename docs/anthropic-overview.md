# Design Proposal: "The Cheapskate’s Proxy" (Internal API Bridge)

**1. Architectural Overview**
A middleware service (`LiteLLM Proxy`) acts as a translation layer between a standard OpenAI-compatible client (Cursor) and the undocumented, unstable Anthropic Internal Web API.

**2. Core Components**

* **Ingress Layer (The Facade):**
  * **Interface:** REST API conforming strictly to OpenAI Chat Completions API (`/v1/chat/completions`).
  * **Authentication:** Accepts a dummy Bearer token (`sk-cursor-claude`) to satisfy client-side validation logic in Cursor.

* **Auth & Session Manager (The Dirty Part):**
  * **Credential Source:** Monitors `~/.claude-session.json` generated by the `claude` CLI utility.
  * **Token Rotation:** Implements a background worker to refresh the `sessionKey` via the refresh token endpoint every 30-55 minutes (pre-empting the 1-hour expiry).
  * **Header Spoofing:** Injects browser-mimicking headers (`User-Agent`, `Origin`, `Referer`) to evade basic WAF rules.

* **Protocol Translator:**
  * **Input Processing:** Converts OpenAI `messages` JSON array into Anthropic’s internal prompt format (likely a specific JSON structure differing from their public API).
  * **Output Processing:** Captures Server-Sent Events (SSE) from the internal API, strips internal metadata/debug info, and repackages the delta content into OpenAI chunk format for streaming.

* **Resilience & Routing:**
  * **Rate Limiter:** Implements a local token bucket to match the vague "Pro" tier limits (approx. every 5 hours) to prevent immediate account banning.
  * **Failover (Optional):** If the internal API returns a 403/429, routing logic switches to a legit paid API key (if configured) or returns a generic error to the client.

**3. Data Flow**

1. **Cursor** sends `POST /v1/chat/completions`.
2. **LiteLLM** intercepts, validates the dummy key.
3. **LiteLLM** reads the current valid session cookie from disk.
4. **LiteLLM** constructs a `POST` request to `https://api.anthropic.com/api/organizations/{org_id}/chat_conversations`.
5. **Anthropic** responds with an SSE stream.
6. **LiteLLM** transforms the stream on-the-fly and pushes it back to Cursor.

**4. Risk Assessment**

* **Stability:** Critical. Dependent on undocumented endpoints.
* **Compliance:** 100% Violation of Anthropic Terms of Service. High risk of account termination.
* **Security:** Session tokens are stored in plaintext on the file system.
